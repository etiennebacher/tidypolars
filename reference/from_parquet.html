<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Import data from Parquet file(s) — from_parquet • tidypolars</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Import data from Parquet file(s) — from_parquet"><meta name="description" content="read_parquet_polars() imports the data as a Polars DataFrame.
scan_parquet_polars() imports the data as a Polars LazyFrame."><meta property="og:description" content="read_parquet_polars() imports the data as a Polars DataFrame.
scan_parquet_polars() imports the data as a Polars LazyFrame."><meta property="og:image" content="https://tidypolars.etiennebacher.com/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">tidypolars</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.13.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/tidypolars.html">Get started</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/faq.html">FAQ</a></li>
    <li><a class="dropdown-item" href="../articles/r-and-polars-expressions.html">R and Polars expressions</a></li>
  </ul></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/etiennebacher/tidypolars/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Import data from Parquet file(s)</h1>
      <small class="dont-index">Source: <a href="https://github.com/etiennebacher/tidypolars/blob/v0.13.0/R/read_scan.R" class="external-link"><code>R/read_scan.R</code></a></small>
      <div class="d-none name"><code>from_parquet.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p><code>read_parquet_polars()</code> imports the data as a Polars DataFrame.</p>
<p><code>scan_parquet_polars()</code> imports the data as a Polars LazyFrame.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">read_parquet_polars</span><span class="op">(</span></span>
<span>  <span class="va">source</span>,</span>
<span>  <span class="va">...</span>,</span>
<span>  n_rows <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  row_index_name <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  row_index_offset <span class="op">=</span> <span class="fl">0L</span>,</span>
<span>  parallel <span class="op">=</span> <span class="st">"auto"</span>,</span>
<span>  hive_partitioning <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  hive_schema <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  try_parse_hive_dates <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  glob <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  rechunk <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  low_memory <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  storage_options <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  use_statistics <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  cache <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  include_file_paths <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">scan_parquet_polars</span><span class="op">(</span></span>
<span>  <span class="va">source</span>,</span>
<span>  <span class="va">...</span>,</span>
<span>  n_rows <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  row_index_name <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  row_index_offset <span class="op">=</span> <span class="fl">0L</span>,</span>
<span>  parallel <span class="op">=</span> <span class="st">"auto"</span>,</span>
<span>  hive_partitioning <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  hive_schema <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  try_parse_hive_dates <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  glob <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  rechunk <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  low_memory <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  storage_options <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  use_statistics <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  cache <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  include_file_paths <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-source">source<a class="anchor" aria-label="anchor" href="#arg-source"></a></dt>
<dd><p>Path to a file. You can use globbing with <code>*</code> to scan/read multiple
files in the same directory (see examples).</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Ignored.</p></dd>


<dt id="arg-n-rows">n_rows<a class="anchor" aria-label="anchor" href="#arg-n-rows"></a></dt>
<dd><p>Maximum number of rows to read.</p></dd>


<dt id="arg-row-index-name">row_index_name<a class="anchor" aria-label="anchor" href="#arg-row-index-name"></a></dt>
<dd><p>If not <code>NULL</code>, this will insert a row index column with
the given name into the DataFrame.</p></dd>


<dt id="arg-row-index-offset">row_index_offset<a class="anchor" aria-label="anchor" href="#arg-row-index-offset"></a></dt>
<dd><p>Offset to start the row index column (only used if
the name is set).</p></dd>


<dt id="arg-parallel">parallel<a class="anchor" aria-label="anchor" href="#arg-parallel"></a></dt>
<dd><p>This determines the direction of parallelism. <code>"auto"</code> will
try to determine the optimal direction. Can be <code>"auto"</code>, <code>"columns"</code>,
<code>"row_groups"</code>, <code>"prefiltered"</code>, or <code>"none"</code>. See 'Details'.</p></dd>


<dt id="arg-hive-partitioning">hive_partitioning<a class="anchor" aria-label="anchor" href="#arg-hive-partitioning"></a></dt>
<dd><p>Infer statistics and schema from Hive partitioned URL
and use them to prune reads. If <code>NULL</code> (default), it is automatically
enabled when a single directory is passed, and otherwise disabled.</p></dd>


<dt id="arg-hive-schema">hive_schema<a class="anchor" aria-label="anchor" href="#arg-hive-schema"></a></dt>
<dd><p>A list containing the column names and data types of the
columns by which the data is partitioned, e.g.
<code>list(a = pl$String, b = pl$Float32)</code>. If <code>NULL</code> (default), the schema of
the Hive partitions is inferred.</p></dd>


<dt id="arg-try-parse-hive-dates">try_parse_hive_dates<a class="anchor" aria-label="anchor" href="#arg-try-parse-hive-dates"></a></dt>
<dd><p>Whether to try parsing hive values as date/datetime
types.</p></dd>


<dt id="arg-glob">glob<a class="anchor" aria-label="anchor" href="#arg-glob"></a></dt>
<dd><p>Expand path given via globbing rules.</p></dd>


<dt id="arg-rechunk">rechunk<a class="anchor" aria-label="anchor" href="#arg-rechunk"></a></dt>
<dd><p>In case of reading multiple files via a glob pattern, rechunk
the final DataFrame into contiguous memory chunks.</p></dd>


<dt id="arg-low-memory">low_memory<a class="anchor" aria-label="anchor" href="#arg-low-memory"></a></dt>
<dd><p>Reduce memory usage (will yield a lower performance).</p></dd>


<dt id="arg-storage-options">storage_options<a class="anchor" aria-label="anchor" href="#arg-storage-options"></a></dt>
<dd><p>Experimental. List of options necessary to scan
parquet files from different cloud storage providers (GCP, AWS, Azure,
HuggingFace). See the 'Details' section.</p></dd>


<dt id="arg-use-statistics">use_statistics<a class="anchor" aria-label="anchor" href="#arg-use-statistics"></a></dt>
<dd><p>Use statistics in the parquet file to determine if pages
can be skipped from reading.</p></dd>


<dt id="arg-cache">cache<a class="anchor" aria-label="anchor" href="#arg-cache"></a></dt>
<dd><p>Cache the result after reading.</p></dd>


<dt id="arg-include-file-paths">include_file_paths<a class="anchor" aria-label="anchor" href="#arg-include-file-paths"></a></dt>
<dd><p>Include the path of the source file(s) as a column
with this name.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>

<div class="section">
<h3 id="on-parallel-strategies">On parallel strategies<a class="anchor" aria-label="anchor" href="#on-parallel-strategies"></a></h3>


<p>The prefiltered strategy first evaluates the pushed-down predicates in
parallel and determines a mask of which rows to read. Then, it parallelizes
over both the columns and the row groups while filtering out rows that do not
need to be read. This can provide significant speedups for large files (i.e.
many row-groups) with a predicate that filters clustered rows or filters
heavily. In other cases, prefiltered may slow down the scan compared other
strategies.</p>
<p>The prefiltered settings falls back to auto if no predicate is given.</p>
</div>

<div class="section">
<h3 id="connecting-to-cloud-providers">Connecting to cloud providers<a class="anchor" aria-label="anchor" href="#connecting-to-cloud-providers"></a></h3>


<p>Polars supports scanning parquet files from different cloud providers.
The cloud providers currently supported are AWS, GCP, and Azure.
The supported keys to pass to the <code>storage_options</code> argument can be found
here:</p><ul><li><p><a href="https://docs.rs/object_store/latest/object_store/aws/enum.AmazonS3ConfigKey.html" class="external-link">aws</a></p></li>
<li><p><a href="https://docs.rs/object_store/latest/object_store/gcp/enum.GoogleConfigKey.html" class="external-link">gcp</a></p></li>
<li><p><a href="https://docs.rs/object_store/latest/object_store/azure/enum.AzureConfigKey.html" class="external-link">azure</a></p></li>
</ul><p>Currently it is impossible to scan public parquet files from GCP without
a valid service account. Be sure to always include a service account in the
<code>storage_options</code> argument.</p>
</div>

<div class="section">
<h3 id="scanning-from-huggingface">Scanning from HuggingFace<a class="anchor" aria-label="anchor" href="#scanning-from-huggingface"></a></h3>


<p>It is possible to scan data stored on HuggingFace using a path starting with
<code>hf://</code>. The <code>hf://</code> path format is defined as
<code>hf://BUCKET/REPOSITORY@REVISION/PATH</code>, where:</p><ul><li><p>BUCKET is one of datasets or spaces</p></li>
<li><p>REPOSITORY is the location of the repository. this is usually in the
format of username/repo_name. A branch can also be optionally specified by
appending <code>@branch</code>.</p></li>
<li><p>REVISION is the name of the branch (or commit) to use. This is optional
and defaults to main if not given.</p></li>
<li><p>PATH is a file or directory path, or a glob pattern from the repository
root.</p></li>
</ul><p>A Hugging Face API key can be passed to access private locations using
either of the following methods:</p><ul><li><p>Passing a token in storage_options to the scan function, e.g.
<code>scan_parquet(..., storage_options = list(token = &lt;your HF token&gt;))</code></p></li>
<li><p>Setting the HF_TOKEN environment variable, e.g.
<code>Sys.setenv(HF_TOKEN = &lt;your HF token&gt;)</code>.</p></li>
</ul></div>

    </div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://www.etiennebacher.com" class="external-link">Etienne Bacher</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>

